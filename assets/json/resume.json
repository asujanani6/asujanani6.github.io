{
  "basics": {
    "name": "Arnesh Sujanani",
    "label": "Postdoctoral Fellow",
    "email": "asujanani6 AT gmail DOT com",
    "website": "https://asujanani6.github.io",
    "summary": "Continuous optimization researcher broadly interested in fast first-order methods, parameter-free optimization, numerical analysis, and semidefinite programming"
  },
  "work": [
    {
      "name": "Department of Combinatorics and Optimization, University of Waterloo",
      "position": "Postdoctoral Fellow",
      "url": "https://uwaterloo.ca/combinatorics-and-optimization/",
      "startDate": "2024-09-01",
      "summary": "Advised by Professors Stephen Vavasis, Henry Wolkowicz, Walaa Moursi, and Saeed Ghadimi"
    }
  ],
  "education": [
    {
      "institution": "Georgia Institute of Technology",
      "url": "https://www.isye.gatech.edu",
      "area": "Fast First-Order Methods for Large-Scale Nonconvex Optimization and Semidefinite Programming",
      "studyType": "PhD in Operations Research (GPA 3.92/4.0)",
      "startDate": "2019-08-15",
      "endDate": "2024-08-01",
      "courses": ["Advised by Renato D.C. Monteiro.", "Committee Members: Arkadi Nemirovski, Alexander Shapiro, Diego Cifuentes, Samuel Burer (External)."]
    },
    {
      "institution": "Georgia Institute of Technology",
      "url": "https://math.gatech.edu",
      "studyType": "M.S. in Mathematics (GPA 4.0/4.0)",
      "startDate": "2019-08-01",
      "endDate": "2024-05-01"
    },
    {
      "institution": "University of Southern California",
      "url": "https://dornsife.usc.edu/mathematics/research/",
      "studyType": "B.S. in Applied and Computational Mathematics (GPA 3.93/4.0)",
      "startDate": "2015-08-01",
      "endDate": "2015-08-01"
    }
  ],
  "publications": [
    {
      "name": "A Low-Rank Augmented Lagrangian Method for Large-Scale Semidefinite Programming Based on a Hybrid Convex-Nonconvex Approach",
      "publisher": "Submitted to Mathematical Programming",
      "releaseDate": "2024-03-31",
      "url": "https://arxiv.org/pdf/2401.12490",
      "summary": "This paper introduces HALLaR, a new first-order method for solving large-scale semidef- inite programs (SDPs) with bounded domain. HALLaR is an inexact augmented Lagrangian (AL) method where the AL subproblems are solved by a novel hybrid low-rank (HLR) method. The recipe behind HLR is based on two key ingredients: 1) an adaptive inexact proximal point method with inner acceleration; 2) Frank-Wolfe steps to escape from spurious local stationary points. In contrast to the low-rank method of Burer and Monteiro, HALLaR finds a near- optimal solution (with provable complexity bounds) of SDP instances satisfying strong duality. Computational results comparing HALLaR to state-of-the-art solvers on several large SDP in- stances arising from maximum stable set, phase retrieval, and matrix completion, show that the former finds highly accurate solutions in substantially less CPU time than the latter ones. For example, in less than 20 minutes, HALLaR can solve a maximum stable set SDP instance with 1 million vertices and 10 million edges within 1e-5 relative precision."
    },
    {
      "name": "An Adaptive Superfast Inexact Proximal Augmented Lagrangian Method for Smooth Nonconvex Composite Optimization Problems",
      "publisher": "Journal of Scientific Computing",
      "releaseDate": "2023-09-23",
      "url": "https://link.springer.com/article/10.1007/s10915-023-02350-y",
      "summary": "This work presents an adaptive superfast proximal augmented Lagrangian (AS-PAL) method for solving linearly-constrained smooth nonconvex composite optimization problems. Each iteration of AS-PAL inexactly solves a possibly nonconvex proximal augmented Lagrangian (AL) subproblem obtained by an aggressive/adaptive choice of prox stepsize with the aim of substantially improving its computational performance followed by a full Lagrange multiplier update. A major advantage of AS-PAL compared to other AL methods is that it requires no knowledge of parameters (e.g., size of constraint matrix, objective function curvatures, etc) associated with the optimization problem, due to its adaptive nature not only in choosing the prox stepsize but also in using a crucial adaptive accelerated composite gradient variant to solve the proximal AL subproblems. The speed and efficiency of AS-PAL is demonstrated through extensive computational experiments showing that it can solve many instances more than ten times faster than other state-of-the-art penalty and AL methods, particularly when high accuracy is required."
    }
  ],
  "interests": [
    {
      "name": "Applied Mathematics",
      "icon": "fa-solid fa-tag",
      "keywords": [
        "Continuous Optimization",
        "Semidefinite Programming",
        "Numerical Analysis",
        "Nonconvex Optimization",
        "First-Order Methods",
        "Parameter-Free Methods"
      ]
    }
  ],
  "skills": [
    {
      "name": "Software",
      "level": "Master",
      "icon": "fa-solid fa-hashtag",
      "keywords": [
        "Julia",
        "Matlab",
        "LaTeX"
      ]
    }
  ]
}
